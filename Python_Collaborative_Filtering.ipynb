{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering\n",
    "- Practice of machine learning with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2, mean_adjustment=False):\n",
    "    if mean_adjustment:\n",
    "        v1 = v1 - np.mean(v1)\n",
    "        v2 = v2 - np.mean(v2)\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:02<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # read MovieLens data\n",
    "    train = pd.read_csv('./data/ua.base', names=[\"user_id\", \"item_id\", \"rating\", \"timestamp\"], sep='\\t')\n",
    "    test  = pd.read_csv('./data/ua.test', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
    "\n",
    "    # create table of index=user_id, columns=item_id\n",
    "    train_rating_mat = pd.pivot_table(train, index='user_id', columns='item_id', values='rating')\n",
    "    train_rating_mat.fillna(0,  inplace=True)\n",
    "\n",
    "    rating_arr = train_rating_mat.values.T\n",
    "    train.set_index('item_id', inplace=True)\n",
    "    precision_list = []\n",
    "\n",
    "    # use five people for evaluation of recommend system\n",
    "    for user1_id in tqdm([1, 100, 233, 666, 888]):\n",
    "        cos_sim_list = []\n",
    "        for user2_index in range(rating_arr.shape[1]):\n",
    "            user1 = rating_arr[:, user1_id-1][:, np.newaxis]\n",
    "            user2 = rating_arr[:, user2_index][:, np.newaxis]\n",
    "            two_users_mat = np.concatenate((user1, user2), axis=1)\n",
    "            two_users_mat = two_users_mat[~np.isnan(two_users_mat).any(axis=1), :]\n",
    "            # calucalate cosine similarity between user1 and user2\n",
    "            cos_sim = cosine_similarity(two_users_mat[:, 0], two_users_mat[:, 1], mean_adjustment=True)\n",
    "            cos_sim_list.append(cos_sim)\n",
    "        cos_sim_mat = pd.Series(cos_sim_list, index=[i for i in range(1, rating_arr.shape[1] + 1)])\n",
    "\n",
    "        # use top 10 users of cosine similarity\n",
    "        top_n = 10\n",
    "        top_n_sim = cos_sim_mat.sort_values(ascending=False)[1:top_n+1]\n",
    "        top_n_users = top_n_sim.index\n",
    "\n",
    "        # test data of user1\n",
    "        test_user1 = test[test['user_id'] == user1_id].sort_values(by='rating', ascending=False)\n",
    "\n",
    "        # calculate the prediction of user1\n",
    "        user1_not_rating = train_rating_mat.iloc[user1_id-1, :]\n",
    "        user1_not_rating = pd.Series(np.logical_not(user1_not_rating), index=user1_not_rating.index)\n",
    "        mean_r = train_rating_mat.replace(0, np.nan).mean(axis=1).drop(labels=[user1_id])\n",
    "        mean_r = mean_r[mean_r.index.isin(top_n_users)]\n",
    "\n",
    "        not_user1_rating_item = train[train.index.isin(user1_not_rating[user1_not_rating == 1].index)]\n",
    "        not_user1_rating_item = not_user1_rating_item[not_user1_rating_item['user_id'].isin(top_n_users)]\n",
    "        not_user1_rating_item.reset_index(inplace=True)\n",
    "\n",
    "        ra = train_rating_mat.replace(0, np.nan).iloc[0, :].mean()\n",
    "        bottom_value = np.sum(top_n_sim)\n",
    "        item_id_list = []\n",
    "        pred_list = []\n",
    "        hits = 0\n",
    "\n",
    "        # recommend top 10 item\n",
    "        for item_id in not_user1_rating_item['item_id'].unique():\n",
    "            rating_by_item = not_user1_rating_item[not_user1_rating_item['item_id'] == item_id]\n",
    "            top_value = np.sum([top_n_sim[uid] * (rating_by_item[rating_by_item['user_id'] == uid]['rating'].values - mean_r[uid]) for uid in rating_by_item['user_id'].values])\n",
    "            pred = ra + top_value / bottom_value\n",
    "            item_id_list.append(item_id)\n",
    "            pred_list.append(pred)\n",
    "\n",
    "        # check the precision of recommend list\n",
    "        pred_dict = {'item_id': item_id_list, 'pred': pred_list}\n",
    "        pred_df = pd.DataFrame.from_dict(pred_dict).sort_values(by='pred', ascending=False).reset_index(drop=True)\n",
    "        recommend_list = pred_df[:10]['item_id'].values\n",
    "        purchase_list = test_user1['item_id'].values\n",
    "        for item_id in recommend_list:\n",
    "            if item_id in purchase_list:\n",
    "                hits += 1\n",
    "        precision_ = hits / 10.0\n",
    "        precision_list.append(precision_)\n",
    "    print('precision: {:.2f}'.format(sum(precision_list) / len(precision_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- [ユーザーベース協調フィルタリング実装](https://leisurelab.hatenablog.com/entry/user-based-cf)\n",
    "\n",
    "    \n",
    "## EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
